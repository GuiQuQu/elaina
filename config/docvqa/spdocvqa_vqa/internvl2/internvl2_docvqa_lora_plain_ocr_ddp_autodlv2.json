{
    "train_dataset": {
        "type": "dataset.docvqa.docvqa_vqa_dataset.DocVQAVqaDataset",
        "dataset_path": "/root/autodl-tmp/SPDocVQA",
        "file_name": "train_v1.0_withQT",
        "preprocess_config": {
            "type": "docvqa_vqa_internvl2_plain_ocr_preprocessor",
            "model_path": "/root/autodl-tmp/pretrain-model/InternVL2-2B",
            "max_seq_length": 3283,
            "max_layout_length": 1024
        }
    },
    "val_dataset": {
        "type": "dataset.docvqa.docvqa_vqa_dataset.DocVQAVqaDataset",
        "dataset_path": "/root/autodl-tmp/SPDocVQA",
        "file_name": "val_v1.0_withQT",
        "preprocess_config": {
            "type": "docvqa_vqa_internvl2_plain_ocr_preprocessor",
            "model_path": "/root/autodl-tmp/pretrain-model/InternVL2-2B",
            "max_seq_length": 3283,
            "max_layout_length": 1024
        }
    },
    "test_dataset": {
        "type": "dataset.docvqa.docvqa_vqa_dataset.DocVQAVqaDataset",
        "dataset_path": "/root/autodl-tmp/SPDocVQA",
        "file_name": "val_v1.0_withQT",
        "preprocess_config": {
            "type": "docvqa_vqa_internvl2_plain_ocr_preprocessor",
            "model_path": "/root/autodl-tmp/pretrain-model/InternVL2-2B",
            "max_seq_length": 3283,
            "max_layout_length": 1024
        }
    },
    "model": {
        "type": "models.docvqa.internvl2_vqa_model.InternVL2VQAModel",
        "model_path": "/root/autodl-tmp/pretrain-model/InternVL2-2B",
        "use_backbone_lora": 0,
        "use_llm_lora": 128,
        "freeze_vision_model": true,
        "freeze_llm_model": true,
        "frzzze_mlp": true,
        "model_dtype": "bf16"
    },
    "output_dir": "/root/autodl-tmp/outputs/SPDocVQA/vqa_ocr_output",
    "data_collator": "dataset.docvqa.collator.internvl2_concat_collator",
    "tester": {
        "type": "tester.internvl2_tester.InternVL2Tester",
        "model_path": "/root/autodl-tmp/pretrain-model/InternVL2-2B",
        "output_dir": "outputs/SPDocVQA/vqa_ocr_output/test_result",
        "generation_config": {
            "max_new_tokens": 128,
            "do_sample": false
        },
        "checkpoint_list": [
            "/root/autodl-tmp/outputs/SPDocVQA/vqa_ocr_output/checkpoint-1000/model.safetensors",
            "/root/autodl-tmp/outputs/SPDocVQA/vqa_ocr_output/checkpoint-4000/model.safetensors",
            "/root/autodl-tmp/outputs/SPDocVQA/vqa_ocr_output/checkpoint-4932/model.safetensors"
        ],
        "dataloader_config": {
            "max_steps": -1,
            "batch_size": 8,
            "num_workers": 4,
            "shuffle": false
        },
        "metrics": [
            {
                "type": "metrics.docvqa_metrics.anls_metrics.ANLSMetrics"
            }
        ]
    },
    "trainer": "trainer.hf_trainer.HFTrainer",
    "training_args": {
        "do_train": true,
        "do_eval": false,
        "do_predict": false,
        "run_name": "train_run_v1",
        "overwrite_output_dir": true,
        "bf16": true,
        "gradient_checkpointing": true,
        "gradient_checkpointing_kwargs": { "use_reentrant": false },
        "remove_unused_columns": true,
        "num_train_epochs": 1,
        "per_device_train_batch_size": 2,
        "dataloader_pin_memory": true,
        "dataloader_prefetch_factor ": 1,
        "dataloader_num_workers": 0,
        "gradient_accumulation_steps": 4,
        "optim": "adamw_torch",
        "learning_rate": 1e-5,
        "max_grad_norm": 1.0,
        "weight_decay": 0.01,
        "lr_scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "evaluation_strategy": "no",
        "save_strategy": "steps",
        "save_steps": 1000,
        "save_safetensors": true,
        "save_total_limit": 5,
        "logging_strategy": "steps",
        "logging_steps": 10,
        "report_to": "tensorboard"
    }
}