{
    "train_dataset": {
        "type": "ensemble_mpdocvqa_vqa_dataset",
        "dataset_path": "/root/autodl-tmp/MPDocVQA",
        "split": "val",
        "ensemble_result_paths": [
            [
                "outputs/MPDocVQA/base_qwen2vl/qwen2vl_vqa_ocr_output/checkpoint-4000-result.json",
                1
            ],
            [
                "outputs/MPDocVQA/base_qwen2vl/qwen2vl_vqa_output/checkpoint-4000-result.json",
                1
            ],
            [
                "outputs/MPDocVQA/base_qwen2vl/internvl2_vqa_ocr_output/checkpoint-4000-result.json",
                0.9
            ],
            [
                "outputs/MPDocVQA/base_qwen2vl/internvl2_vqa_output/checkpoint-4000-result.json",
                0.7
            ]
        ],
        "preprocess_config": {
            "type": "mpdocvqa_cot_vqa_qwen2vl_train_preprocessorv1",
            "model_path": "/root/autodl-tmp/pretrain-model/Qwen2-VL-2B-Instruct",
            "max_seq_length": 2048
        }
    },
    "test_dataset": {
        "type": "ensemble_mpdocvqa_vqa_dataset",
        "dataset_path": "/root/autodl-tmp/MPDocVQA",
        "include_func": null,
        "split": "test",
        "ensemble_result_paths": [
            [
                "testdataset_result/MPDocVQA/base_internvl2/qwen2vl_vqa_ocr_output/checkpoint-4000-result.json",
                1
            ],
            [
                "testdataset_result/MPDocVQA/base_internvl2/qwen2vl_vqa_output/checkpoint-4000-result.json",
                1
            ],
            [
                "testdataset_result/MPDocVQA/base_internvl2/internvl2_vqa_ocr_result/checkpoint-4000-result.json",
                0.9
            ],
            [
                "testdataset_result/MPDocVQA/base_internvl2/internvl2_vqa_result/checkpoint-4000-result.json",
                0.7
            ]
        ],
        "preprocess_config": {
            "type": "mpdocvqa_cot_vqa_qwen2vl_test_preprocessorv1",
            "model_path": "/root/autodl-tmp/pretrain-model/Qwen2-VL-2B-Instruct",
            "classify_result_path": "testdataset_result/MPDocVQA/qwen2vl_classify_output/test_result/checkpoint-41184-result.json",
            "max_seq_length": 2048
        }
    },
    "model": {
        "type": "qwen2vl_vqa_model",
        "model_path": "/root/autodl-tmp/pretrain-model/Qwen2-VL-2B-Instruct",
        "warp_qwen2vl_lora": 64,
        "freeze_vision_model": true,
        "freeze_llm_model": true,
        "model_dtype": "bf16"
    },
    "output_dir": "/root/autodl-tmp/outputs/MPDocVQA/qwen2vl_ensemble_cot_vqa_output_v4",
    "data_collator": "qwen2vl_concat_collator",
    "tester": {
        "type": "custom_tester",
        "output_dir": "testdataset_result/MPDocVQA/base_internvl2/qwen2vl_ensemble_cot_vqa_output_v4/test_result",
        "checkpoint_list": [
            "/root/autodl-tmp/outputs/MPDocVQA/qwen2vl_ensemble_cot_vqa_output_v4/checkpoint-547/pytorch_model.bin"
        ],
        "dataloader_config": {
            "max_steps": -1,
            "batch_size": 4,
            "num_workers": 4,
            "shuffle": false
        },
        "metrics": [
            {
                "type": "metrics.docvqa_metrics.anls_metrics.ANLSMetrics",
                "pred_key": "model_output",
                "answers_key": "answers"
            }
        ]
    },
    "trainer": "hf_trainer",
    "training_args": {
        "do_train": true,
        "do_eval": false,
        "do_predict": false,
        "run_name": "train_run_v1",
        "overwrite_output_dir": true,
        "bf16": true,
        "gradient_checkpointing": true,
        "gradient_checkpointing_kwargs": {
            "use_reentrant": false
        },
        "remove_unused_columns": true,
        "num_train_epochs": 1,
        "per_device_train_batch_size": 2,
        "dataloader_pin_memory": true,
        "dataloader_prefetch_factor ": 1,
        "dataloader_num_workers": 0,
        "gradient_accumulation_steps": 4,
        "optim": "adamw_torch",
        "learning_rate": 1e-5,
        "max_grad_norm": 1.0,
        "weight_decay": 0.01,
        "lr_scheduler_type": "cosine",
        "warmup_ratio": 0.1,
        "evaluation_strategy": "no",
        "save_strategy": "steps",
        "save_steps": 1000,
        "save_safetensors": false,
        "save_total_limit": 5,
        "logging_strategy": "steps",
        "logging_steps": 10,
        "report_to": "tensorboard"
    }
}